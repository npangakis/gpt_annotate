# gpt_annotate
Introducing gpt_annotate: an easy-to-use python package designed to streamline automated text annotation using LLMs for different tasks and datasets. 

All you need is an OpenAI API key, text samples you want to annotate, and a codebook (i.e., task-specific instructions) for the LLM.
* OpenAI API key (sign up for one here: https://platform.openai.com/account/api-keys)
* text_to_annotate: 
	* A dataframe that includes one column for text samples and, if you are comparing the LLM output against humans, any number of one-hot-encoded category columns. We provide Python code (described below) that will automatically assist with the formatting of text_to_annotate to ensure accurate annotation.
* codebook: 
	* Task-specific instructions (as type string) to prompt the LLM to annotate the data. Like codebooks for qualitative content analysis, this should clearly describe the dataset, the type of task for the LLM, and, most importantly, delineate the categories of interest for the LLM to annotate. We provide Python code to standardize the beginning and ending of the codebook to ensure that the LLM understands that the task is annotation.

To annotate your text data using gpt_annotate, we recommend following the sample code we provide in `sample_annotation_code.ipynb`.

As shown in `sample_annotation_code.ipynb`, annotating your text data with LLMs is as easy as 4 simple steps:
1. Import the required dependencies (including gpt_annotate.py).

```
import openai
import pandas as pd
import math
import time
import numpy as np
import tiktoken
#### Import main package: gpt_annotate.py
# Make sure that the .py file is in the same directory as the .ipynb file, or you provide the correct relative or absolute path to the .py file.
import gpt_annotate
```

2. Read in your codebook (i.e., task-specific instructions) and the text samples you want to annotate.

```
	text_to_annotate = pd.read_csv("text_to_classify.csv")
	with open('codebook.txt', 'r') as file:
    		codebook = file.read()
 ```
    
3. To ensure your data is in the right format, you must first run gpt_annotate.prepare_data(text_to_annotate, codebook, key). If you are annotating text data without any human labels to compare against, change the default to human_labels = False. If you want to add standardized language to the beginning and end of your codebook to ensure that GPT will label your text samples, change the default to prep_codebook = True.
```
	text_to_annotate = gpt_annotate.prepare_data(text_to_annotate, codebook, key)
```
4. If comparing LLM output to human labels, run gpt_annotate.gpt_annotate(text_to_annotate, codebook, key). If only using gpt_annotate for prediction (i.e., no human labels to compare performance), run gpt_annotate.gpt_annotate(text_to_annotate, codebook, key, human_labels = False). Itâ€™s as easy as that!
```
	# Annotate the data (returns 4 outputs)
	gpt_out_all, gpt_out_final, performance, incorrect =  gpt_annotate.gpt_annotate(text_to_annotate, codebook, key)
```

Below we define the alternative parameters within `gpt_annotate()` to customize your annotation procedures.
* num_iterations:
	* Number of times to classify each text sample. Default is 3.
* model:
	* OpenAI GPT model, which is either gpt-3.5-turbo or gpt-4. Default is gpt-4.
* temperature: 
	* LLM temperature parameter (ranges 0 to 1), which indicates the degree of diversity to introduce into the model. Default is 0.6.
* batch_size:
	* Number of text samples to be annotated in each batch. Default is 10.
* human_labels: 
	* Boolean indicating whether text_to_annotate has human labels to compare LLM outputs to. 
* data_prep_warning: 
	* Boolean indicating whether to print data_prep_warning
* time_cost_warning: 
	* Boolean indicating whether to print time_cost_warning


Please email us (njpang@sas.upenn.edu) with any suggestions or problems encountered with the code.
